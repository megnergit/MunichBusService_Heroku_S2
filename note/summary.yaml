    note1: <b style="color:salmon">CAUTION 1</b> </br>

        This is a **mock-up** dashboard. The contents do not reflect
	the actual
        sentiments of the tweets. This is because I used up the credits to
        send the queries to the sentiment-analysis API by MonkeyLearn during
        the code-development phase. Currently the App is working with a dummy
        sentiment-analysis function that returns random values.

    note2: <b style="color:salmon">CAUTION 2</b> </br>
        If you are using **safari** browser, and do **not see anything** on the
        browser when you open the URL of the App, you should **update** your
        safari to the newest version. I had this problem myself.

    note3: <b style="color:salmon">CAUTION 3</b> </br>
        As you see below, the App uses a number of APIs. The **API keys** are
        stored locally in the file 'config.py', and not given in the GitHub
        repo (the API keys are stamped out). You can obtain
	the API keys yourself by creating your own
        account at each service, and plug them in the file. 

    what: "### What the App does 

        1. Collect **tweets** that contain the word '**bus**', and 
        are sent from **20 km** from MarienPlatz. **Twitter API** was used.
        The majority of the tweets about a bus are from '**MVVticker**'
        reporting delays, accidents, and coming back to the
        normality. Tweets by the user 'MVVticker' are removed.

        2. Translate **German** texts to **English**, using **DeepL API**, 
        to apply the sentiment analysis that works only in Englith.

        3. **Sentiments** and **keywords** are extracted from the texts. 
        **MonkeyLearn APIs** are used. The sentiments are weighted by the 
        'confidence' (that comes with the sentiment analysis), and are 
        averaged to the overall sentiment. The neutral sentiments are 
        not counted (weighted to zero).

        4. Use **`plotly`** (for the diagrams and the pie charts), 
        **`foilum`** (map), 
        and **`wordcloud`** (wordcloud) to create the **visualizations**.

        5. Put the visualizations into a **dynamic webpage** using 
        **`streamlit`**.

        6. **Deploy** the App on **`Heroku`**."

    table: "### Tech Stack 

        |A                              | B                           |
        |-------------------------------|-----------------------------|
        |Coding                         | Python                      |
        |Data source                    | Twitter                     |   
        |Translation                    | DeepL                       |   
        |Sentiment / Keyword extraction | MonkeyLearn                 |   
        |Visualization                  | plotly, folium, wordcloud   |
        |Webpage                        | streamlit                   |   
        |Deployment                     | Heroku                      |   
        "

    questions: "How people are satisfied  with the bus service in Munich?
        The project will try to see if we could answer the three questions below. 
        <style>
        p {
            padding-left:40px
        }
        </style>
        <p>
        <ul> 
        <li> **If** people in Munich are satisfied with their bus service.</li>
        <li> **What** people are satisfied and unsatisfied with.</li>
        <li> **Which part of the city**, people are most unsatisfied.</li>
        </ul>
        </p>
        "
    conclusions: "### Conclusions
            
        There are a few difficulties to answer the questions. 
        <style>
        p {
            padding-left:40px
        }
        </style>
        <p>
        <ol>
        <li> The number of accessible tweets are too small. We have about **10-30
        tweets per day** on the bus in Munich, and not all of them are 
        useful to extract clear **sentiments**. Much more is  necessary to be 
        statistically  significant in the **keyword** collections.</li>
        <li> Almost **none** of the tweets accessible in a free plan come with 
        **geo tags**. The granularity of the localization is not enough to 
        identify the hot spots of dissatisfaction. </li>
        </ol>
        </p>
        Further discussion will be found in my [GitHub repo](
https://github.com/megnergit/MunichBusService_Heroku_S2/blob/main/README.md).
        "
    map_caption: "### Lack of Coordinate Infomation

        In the map below, there are two big circles near
        **Maxvorstadt** and **Pasing**, each actually consists of 
        many concentric circles. 
        The location, Maxforstat, for instance, only reflects that 
        the tweets come from the city Munich. 
        When the tweet-authors open their geo-location as
        'Munich', the coordinate (11.57540E, 48.13714N; near Maxvorstadt) 
        is automatically  assigned.  The same probably applies to Pasing. 
        The granularity is way too coarse to identify a street. 
        "

    pie_chart_caption: "### Inner city vs. Suburbs

        Here 'inner city' is defined by RADIUS_INNEN from 
        **Marien Platz**, which roughly corresponds to inside the **Mittlerer Ring**.
        The outer boundary of the 'outer city' is set at the radius RADIUS.
        "
